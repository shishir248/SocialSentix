{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef89374a-7fe1-4f48-b367-c88b4212b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc688b6-dbf8-4f97-a10f-64847e628038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb8df03-a692-48c3-a8da-69ffaed021fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_json = dict()\n",
    "ticker_col = df['tickers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b725d04-8efb-4491-9c21-b16eb03b4284",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    # Parse the tickers string into a list of tickers\n",
    "    tickers = ast.literal_eval(row['tickers'])\n",
    "    comments = []\n",
    "    # Iterate through the tickers for this comment\n",
    "    for ticker in tickers:\n",
    "        # Create a comment object for this comment\n",
    "        comment = {\n",
    "            'id': row['id'],\n",
    "            'url': row['url'],\n",
    "            'body': row['body'],\n",
    "            'timestamp': row['timestamp'],\n",
    "            'score': row['sentiment']\n",
    "        }\n",
    "        \n",
    "        # If the ticker is not in the dictionary, add it with an empty list\n",
    "        if ticker not in ticker_dict:\n",
    "            ticker_dict[ticker] = []\n",
    "        \n",
    "        # Append the comment object to the ticker's list\n",
    "        ticker_dict[ticker].append({'comment': comment})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cde22b3-2858-4837-b826-46e8111d5096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(ticker_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a04f5c-5b9f-4192-8c95-9d9ce6f740e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d6b762a5-e4fc-4a6d-b10e-d3d79f1c1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"\"\"Return the first n items of the iterable as a list.\"\"\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "096780a1-bb81-4a9c-a997-771fa7ee2a39",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1088278597.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[268], line 22\u001b[0;36m\u001b[0m\n\u001b[0;31m    ticker_dict[ticker].update('comments',.append({comment})\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ticker_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    # Parse the tickers string into a list of tickers\n",
    "    tickers = ast.literal_eval(row['tickers'])\n",
    "\n",
    "    # Iterate through the tickers for this comment\n",
    "    for ticker in tickers:\n",
    "        ticker_dict[ticker] = {}\n",
    "        # Create a comment object for this comment\n",
    "        comment = {\n",
    "            'id': row['id'],\n",
    "            'url': row['url'],\n",
    "            'body': row['body'],\n",
    "            'timestamp': row['timestamp'],\n",
    "            'score': row['sentiment']\n",
    "        }\n",
    "        \n",
    "        # If the ticker is not in the dictionary, add it with an empty list\n",
    "        if ticker not in ticker_dict:\n",
    "            ticker_dict[ticker]['comments']= []\n",
    "        # Append the comment object to the ticker's list\n",
    "        ticker_dict[ticker].update('comments',.append({comment})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6818744f-1464-4906-a027-0c65646ec636",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open('./data.json', \"r+\")\n",
    "data = json.load(data_file)\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c62366-ccb5-4ccd-92df-1ec2039e9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = []\n",
    "for ticker, value in data.items():\n",
    "    test[ticker] = {}\n",
    "    test[ticker][\"comments\"] = value\n",
    "    new_dict.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a69fd9d9-510e-4b6d-b6ad-a0a0524678dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[262], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/json/encoder.py:429\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/json/encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/json/encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/json/encoder.py:385\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m _key_separator\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnull\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('symbol.json', 'w') as fp:\n",
    "    json.dump(new_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "845eb876-37fd-4ece-a3f7-0a68ea3e9efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    # Parse the tickers string into a list of tickers\n",
    "    tickers = ast.literal_eval(row['tickers'])\n",
    "    comments = []\n",
    "    # Iterate through the tickers for this comment\n",
    "    for ticker in tickers:\n",
    "        # Create a comment object for this comment\n",
    "        comment = {\n",
    "            'id': row['id'],\n",
    "            'url': row['url'],\n",
    "            'body': row['body'],\n",
    "            'timestamp': row['timestamp'],\n",
    "            'unix': row['created'],\n",
    "            'score': row['sentiment']\n",
    "        }\n",
    "        \n",
    "        # If the ticker is not in the dictionary, add it with an empty list\n",
    "        if ticker not in ticker_dict:\n",
    "            ticker_dict[ticker] = {'comments':[]}\n",
    "        \n",
    "        # Append the comment object to the ticker's list\n",
    "        ticker_dict[ticker]['comments'].append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de0ccfe6-818c-4f4c-836e-5d5d578e22c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('symbol.json', 'w') as fp:\n",
    "    json.dump(ticker_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a66476a-8822-471b-bf63-7d7a562a4d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_dict_new = {}\n",
    "for t, d in ticker_dict.items():\n",
    "    total_sentiment_score = 0\n",
    "    total_comments = len(d['comments'])\n",
    "    for comment in d['comments']:\n",
    "        total_sentiment_score += comment['score']\n",
    "    avg_score = total_sentiment_score/total_comments\n",
    "    ticker_dict_new.update({t: {'total_score': avg_score, 'comments': d['comments']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "330f90a5-79de-427f-b890-3812f255218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('symbol.json', 'w') as fp:\n",
    "    json.dump(ticker_dict_new, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b4d1b4-0584-43be-abdc-c213602496d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word cloud\n",
    "import json\n",
    "with open ('symbol.json', 'r') as r:\n",
    "    new_d = json.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4b1c0f0-96da-495e-841a-6c87691ba117",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'assets/wordcloud_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12b023a8-c613-429b-b46d-40bfc260d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d44817c3-5a2b-4d94-a595-801b92828fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d670894-3b10-4235-9235-002428ab82a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: WordCloud in /Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/lib/python3.10/site-packages (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/lib/python3.10/site-packages (from WordCloud) (1.26.0)\n",
      "Requirement already satisfied: pillow in /Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/lib/python3.10/site-packages (from WordCloud) (10.0.1)\n",
      "Requirement already satisfied: matplotlib in /Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/lib/python3.10/site-packages (from WordCloud) (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/lib/python3.10/site-packages (from matplotlib->WordCloud) (23.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/lib/python3.10/site-packages (from matplotlib->WordCloud) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/lib/python3.10/site-packages (from matplotlib->WordCloud) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/lib/python3.10/site-packages (from matplotlib->WordCloud) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/lib/python3.10/site-packages (from matplotlib->WordCloud) (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/lib/python3.10/site-packages (from matplotlib->WordCloud) (0.12.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/lib/python3.10/site-packages (from matplotlib->WordCloud) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->WordCloud) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/shikua/.pyenv/versions/3.10.0/envs/socialsentix/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fa968cb-e62e-4e43-97cd-543d4d92fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88aea8ab-a4c8-4cb7-ab92-42b6cc23ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS\n",
    "stop_words = [\"https\", \"png\", \"preview\", \"webp\", \"format\"] + list(STOPWORDS)\n",
    "for s,v in new_d.items():\n",
    "    comments = ' '\n",
    "    img_path = os.path.join(output_dir,f'{s}_wordcloud.png')\n",
    "    for comm in v['comments'][:5]:\n",
    "        comments += comm['body'] + \" \"\n",
    "    wordcloud = WordCloud(width = 800, height=400, background_color='#d2e9e9', stopwords=stop_words).generate(comments)\n",
    "    wordcloud.to_file(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90e3fe1d-6ff9-4952-938c-32d90815204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,v in new_d.items():\n",
    "    new_d[s]['img_path'] = f'/assets/{s}_wordcloud.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28def2f2-f12c-4c5b-b49c-40622c1d9f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cf50691-1d8d-4dc2-8388-6cfff907ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./symbol_wordlcloud.json', 'w') as fp:\n",
    "    json.dump(new_d, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4efd4-8248-4218-86fa-3019fcdff646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4507a0-38ac-4cdb-9c73-a11345ff9bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a514c1-f3b9-4b69-b73c-b5d5312a1065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3135ba9-39e2-44e6-b564-8438c1a032e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df0415-9147-4b0a-a82e-b2f37d3887b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452858c-4f5a-4407-a587-b40f68d548a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e9b83-883b-470c-854f-c6895a292ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b33c3-b8f3-40f9-8725-a715c53ca3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaa4134-3952-4042-9e0c-828c2d94222c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cd741c0-faf2-4103-b544-44d0f013933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neew things\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "223db2c9-bc00-4faf-b20f-124fb1cf9917",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32f56a9c-e1fa-4957-a313-586d974aaf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_json = dict()\n",
    "ticker_col = df['tickers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f30142d4-8b29-4663-a67d-d75b165c7b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    # Parse the tickers string into a list of tickers\n",
    "    tickers = ast.literal_eval(row['tickers'])\n",
    "    comments = []\n",
    "    # Iterate through the tickers for this comment\n",
    "    for ticker in tickers:\n",
    "        # Create a comment object for this comment\n",
    "        comment = {\n",
    "            'id': row['id'],\n",
    "            'url': row['url'],\n",
    "            'body': row['body'],\n",
    "            'timestamp': row['timestamp'],\n",
    "            'unix': row['created'],\n",
    "            'pos_score': row['pos_score'],\n",
    "            'neg_score': row['neg_score'],\n",
    "            'compound_score': row['compound_score']\n",
    "        }\n",
    "        \n",
    "        # If the ticker is not in the dictionary, add it with an empty list\n",
    "        if ticker not in ticker_dict:\n",
    "            ticker_dict[ticker] = {'comments':[]}\n",
    "        \n",
    "        # Append the comment object to the ticker's list\n",
    "        ticker_dict[ticker]['comments'].append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6221a3c6-0e35-454f-973f-a5dd353213be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_dict_new = {}\n",
    "for t, d in ticker_dict.items():\n",
    "    total_pos_score = 0\n",
    "    total_neg_score = 0\n",
    "    total_compound_score = 0\n",
    "    concat_comments = ''\n",
    "    total_comments = len(d['comments'])\n",
    "    for comment in d['comments']:\n",
    "        total_pos_score += comment['pos_score']\n",
    "        total_neg_score += comment['neg_score']\n",
    "        total_compound_score += comment['compound_score']\n",
    "        concat_comments += comment['body']\n",
    "    pos_avg_score = total_pos_score/total_comments\n",
    "    neg_avg_score = total_neg_score/total_comments\n",
    "    compound_avg_score = total_compound_score/total_comments\n",
    "    ticker_dict_new.update({t: {'total_pos_score': pos_avg_score, 'total_neg_score': neg_avg_score, 'total_compound_score': compound_avg_score, 'concatenated_comments': concat_comments, 'comments': d['comments']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b403db0b-c1f1-410b-9587-68ab4c1d8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bardapi import Bard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6eaed89c-a89b-4e56-b175-b5533c412260",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'bgjoHVx1zno9kTEoks1Pdsihc6v5AfQ8CkMLLlAlhdZNun_xDBKtekepjGkbHggtwsEubQ.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8440148a-2cea-4708-bccb-b089b8a928a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, d in ticker_dict_new.items():\n",
    "    ques = f'Summarize in 60 words maximum the public sentiments of {t} from these comments f{d[\"concatenated_comments\"]}'\n",
    "    ticker_dict_new[t]['bard'] = Bard(token=token).get_answer(ques)['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "204fca2e-dde0-456e-9981-4ec7015e8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./new.json', 'w') as fp:\n",
    "    json.dump(ticker_dict_new, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0173251e-c816-4602-9676-d4cd01811817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
